{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"assignment_2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del data[\"bias\"]\n",
    "data[\"salary\"] = 0.0001 * data[\"salary\"]\n",
    "\n",
    "\n",
    "\n",
    "X = data[[\"experience\", \"salary\"]]#.values\n",
    "T = data[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Rule 정리  \n",
    "\n",
    "$ h = W_{1}X_{1} + W_{2}X_{2} + b  $  \n",
    "$ p = \\frac{1}{1 + exp(-h)}  $  \n",
    "$ L^* =  \\sum_{i}^{N}{t_{i} log(p) + (1-t_{i})log(1-p) } $  \n",
    "$ J^* = - \\sum_{i}^{N}{t_{i} log(p) + (1-t_{i})log(1-p) } $  \n",
    "\n",
    "$ \\frac{\\partial{J^*}}{\\partial{p}} = - \\sum_{i}^{N}{( \\frac{t_i}{p_i} - \\frac{1-t_i}{1-p_i} )} $  \n",
    "$ \\frac{\\partial{p_i}}{\\partial{h}} = p_i(1-p_i)$  \n",
    "$ \\frac{\\partial{h}}{\\partial{W_i}} = X_i $  \n",
    "$ \\frac{\\partial{h}}{\\partial{b}} = 1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.params = {}\n",
    "        self.params['W'] = 0.01 * np.random.randn(2, 1)\n",
    "        self.params['b'] = np.ones(1)\n",
    "    def forward(self, X):\n",
    "        #Sigmoid 함수\n",
    "        W = self.params['W']\n",
    "        b = self.params['b']\n",
    "        h = np.dot(X, W) + b\n",
    "        p = 1 / (1 + np.exp(-h))\n",
    "        \n",
    "        return p\n",
    "    \n",
    "    def loss(self, X, T):\n",
    "        \n",
    "        p = self.forward(X)\n",
    "        \n",
    "        #Log_Likelihood\n",
    "        L = np.dot(T.reshape(1,200), np.log(p)) + np.dot(1 - T.reshape(1,200), np.log(1 - p))\n",
    "        L = np.squeeze(L)\n",
    "        #for i in range(len(X)):\n",
    "        #for문으로 각 데이터의 Log_Likelihood를 더해준다.\n",
    "        #    L += ( T[i] * np.log(p[i]) + (1 - T[i]) * np.log(1 - p[i]) )\n",
    "        \n",
    "        #목적함수는 -Log_Likelihood\n",
    "        return -L\n",
    "    \n",
    "    def gradient(self, X, T, learning_rate = 0.0001):\n",
    "        \n",
    "        p = self.forward(X)\n",
    "        X = X.values\n",
    "        T = np.array(T)\n",
    "        T = T.reshape(-1,1)\n",
    "        #목적함수에 대한 가중치 미분값을 담을 zero array 생성\n",
    "        grads = {}\n",
    "        grads['W'] = np.zeros((2, 1))\n",
    "        grads['b'] = np.zeros(1)\n",
    "        \n",
    "        #목적함수에 대한 가중치 미분값 합 구하기\n",
    "        grads['W'] = -np.dot(X.T, (T - T*p) - (p - T*p))\n",
    "        grads['b'] = -np.sum((T - T*p) - (p - T*p))\n",
    "#         for i in range(len(X)):\n",
    "#             #for문으로 가중치에 대한 목적함수 미분 값 모두 더하기\n",
    "#             grads['W'] -= ((T[i] * (1-p[i])) - ((1-T[i]) * p[i])) * X[i].reshape(2,1)\n",
    "#             #print(i, \":  \", grads['W'])\n",
    "#             grads['b'] -= ((T[i] * (1-p[i])) - ((1-T[i]) * p[i])) * 1\n",
    "            \n",
    "#             if i == len(X) - 1:\n",
    "#                 grads['W'] /= len(X)\n",
    "#                 grads['b'] /= len(X)\n",
    "        self.params['W'] -= learning_rate * grads['W']\n",
    "        self.params['b'] -= learning_rate * grads['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72567002],\n",
       "       [0.72609135],\n",
       "       [0.72488464],\n",
       "       [0.72512792],\n",
       "       [0.72422313],\n",
       "       [0.72522747],\n",
       "       [0.72475144],\n",
       "       [0.72354108],\n",
       "       [0.72434537],\n",
       "       [0.72480316],\n",
       "       [0.72629511],\n",
       "       [0.72463824],\n",
       "       [0.72527616],\n",
       "       [0.72425837],\n",
       "       [0.72567975],\n",
       "       [0.72341943],\n",
       "       [0.72427111],\n",
       "       [0.72477012],\n",
       "       [0.72482995],\n",
       "       [0.72528805],\n",
       "       [0.72407237],\n",
       "       [0.72590099],\n",
       "       [0.72358235],\n",
       "       [0.72540244],\n",
       "       [0.7237273 ],\n",
       "       [0.72629296],\n",
       "       [0.72223105],\n",
       "       [0.72555868],\n",
       "       [0.72629674],\n",
       "       [0.7232646 ],\n",
       "       [0.72188373],\n",
       "       [0.72416456],\n",
       "       [0.72587101],\n",
       "       [0.72570515],\n",
       "       [0.72419168],\n",
       "       [0.72598902],\n",
       "       [0.72772043],\n",
       "       [0.72313988],\n",
       "       [0.72630186],\n",
       "       [0.72408213],\n",
       "       [0.72459789],\n",
       "       [0.72542785],\n",
       "       [0.72567002],\n",
       "       [0.72655326],\n",
       "       [0.72738035],\n",
       "       [0.72613022],\n",
       "       [0.72687836],\n",
       "       [0.72454994],\n",
       "       [0.7240363 ],\n",
       "       [0.72457243],\n",
       "       [0.72542785],\n",
       "       [0.72705725],\n",
       "       [0.72609513],\n",
       "       [0.72594798],\n",
       "       [0.72470947],\n",
       "       [0.72443371],\n",
       "       [0.7275776 ],\n",
       "       [0.724824  ],\n",
       "       [0.72411061],\n",
       "       [0.72473113],\n",
       "       [0.72486975],\n",
       "       [0.72493418],\n",
       "       [0.72489438],\n",
       "       [0.72347048],\n",
       "       [0.72754343],\n",
       "       [0.7254757 ],\n",
       "       [0.72681125],\n",
       "       [0.7258883 ],\n",
       "       [0.72572244],\n",
       "       [0.72465558],\n",
       "       [0.72187692],\n",
       "       [0.72728291],\n",
       "       [0.72628405],\n",
       "       [0.72454831],\n",
       "       [0.72505162],\n",
       "       [0.7246331 ],\n",
       "       [0.72374304],\n",
       "       [0.72460683],\n",
       "       [0.72395385],\n",
       "       [0.7245326 ],\n",
       "       [0.72596067],\n",
       "       [0.72649959],\n",
       "       [0.72429957],\n",
       "       [0.72221144],\n",
       "       [0.72393215],\n",
       "       [0.72258707],\n",
       "       [0.72569542],\n",
       "       [0.7272471 ],\n",
       "       [0.72314287],\n",
       "       [0.72566111],\n",
       "       [0.72400267],\n",
       "       [0.72683362],\n",
       "       [0.72498127],\n",
       "       [0.72448167],\n",
       "       [0.72474088],\n",
       "       [0.72609135],\n",
       "       [0.72610269],\n",
       "       [0.72584859],\n",
       "       [0.72288654],\n",
       "       [0.72405881],\n",
       "       [0.72331051],\n",
       "       [0.72527832],\n",
       "       [0.72427788],\n",
       "       [0.72382037],\n",
       "       [0.72858559],\n",
       "       [0.72404308],\n",
       "       [0.72550787],\n",
       "       [0.72371969],\n",
       "       [0.7236589 ],\n",
       "       [0.72618393],\n",
       "       [0.72405366],\n",
       "       [0.72583374],\n",
       "       [0.72461278],\n",
       "       [0.72311135],\n",
       "       [0.7244944 ],\n",
       "       [0.72533295],\n",
       "       [0.72428087],\n",
       "       [0.7233901 ],\n",
       "       [0.72328796],\n",
       "       [0.72532997],\n",
       "       [0.72490331],\n",
       "       [0.72314369],\n",
       "       [0.72534863],\n",
       "       [0.72541298],\n",
       "       [0.72614372],\n",
       "       [0.7237851 ],\n",
       "       [0.72398016],\n",
       "       [0.72554598],\n",
       "       [0.72475361],\n",
       "       [0.72506516],\n",
       "       [0.72523937],\n",
       "       [0.72542569],\n",
       "       [0.72627946],\n",
       "       [0.72563273],\n",
       "       [0.72397338],\n",
       "       [0.72663092],\n",
       "       [0.72364315],\n",
       "       [0.72466072],\n",
       "       [0.72545705],\n",
       "       [0.72483375],\n",
       "       [0.72248394],\n",
       "       [0.72587776],\n",
       "       [0.72547273],\n",
       "       [0.72633019],\n",
       "       [0.72503133],\n",
       "       [0.72393133],\n",
       "       [0.72687917],\n",
       "       [0.72768628],\n",
       "       [0.72496557],\n",
       "       [0.72368061],\n",
       "       [0.72472301],\n",
       "       [0.72575459],\n",
       "       [0.72515417],\n",
       "       [0.72634665],\n",
       "       [0.72561328],\n",
       "       [0.72621902],\n",
       "       [0.72243196],\n",
       "       [0.72472436],\n",
       "       [0.72757464],\n",
       "       [0.72309178],\n",
       "       [0.72581132],\n",
       "       [0.72299257],\n",
       "       [0.72476715],\n",
       "       [0.72586588],\n",
       "       [0.72246898],\n",
       "       [0.72645267],\n",
       "       [0.72431908],\n",
       "       [0.72346885],\n",
       "       [0.72451012],\n",
       "       [0.72568056],\n",
       "       [0.72500373],\n",
       "       [0.72679643],\n",
       "       [0.72432884],\n",
       "       [0.7241624 ],\n",
       "       [0.72591666],\n",
       "       [0.7256911 ],\n",
       "       [0.72511521],\n",
       "       [0.72541812],\n",
       "       [0.72530293],\n",
       "       [0.72434754],\n",
       "       [0.7243993 ],\n",
       "       [0.72506055],\n",
       "       [0.72523342],\n",
       "       [0.72556625],\n",
       "       [0.72537702],\n",
       "       [0.72535079],\n",
       "       [0.72335098],\n",
       "       [0.72510168],\n",
       "       [0.72618474],\n",
       "       [0.72514361],\n",
       "       [0.72568948],\n",
       "       [0.723695  ],\n",
       "       [0.72415562],\n",
       "       [0.72690369],\n",
       "       [0.72270678],\n",
       "       [0.72345093],\n",
       "       [0.7248952 ],\n",
       "       [0.72437979],\n",
       "       [0.72614075],\n",
       "       [0.72520584]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207.51009840575531"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.loss(X, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 Loss :  158.4467700417873\n",
      "10000 번째 Loss :  62.36471904996918\n",
      "20000 번째 Loss :  59.18415080410321\n",
      "30000 번째 Loss :  58.16913455852484\n",
      "40000 번째 Loss :  57.78074015690351\n",
      "50000 번째 Loss :  57.61687358900315\n",
      "60000 번째 Loss :  57.54362663923894\n",
      "70000 번째 Loss :  57.50967706284162\n",
      "80000 번째 Loss :  57.49356503221238\n",
      "90000 번째 Loss :  57.48579652936336\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    l.gradient(X, T)\n",
    "    if i % 10000 == 0:\n",
    "        print(i, \"번째 Loss : \", l.loss(X, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W': array([[ 1.57954519],\n",
       "        [-2.80430511]]), 'b': array([8.71044982])}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
