{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression 에서 MLE에 대한 GD 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Rule 정리  \n",
    "\n",
    "$ h = W_{1}X_{1} + W_{2}X_{2} + b  $  \n",
    "$ p = \\frac{1}{1 + exp(-h)}  $  \n",
    "$ L^* =  \\sum_{i}^{N}{t_{i} log(p) + (1-t_{i})log(1-p) } $  \n",
    "$ J^* = - \\sum_{i}^{N}{t_{i} log(p) + (1-t_{i})log(1-p) } $  \n",
    "\n",
    "$ \\frac{\\partial{J^*}}{\\partial{p}} = - \\sum_{i}^{N}{( \\frac{t_i}{p_i} - \\frac{1-t_i}{1-p_i} )} $  \n",
    "$ \\frac{\\partial{p_i}}{\\partial{h}} = p_i(1-p_i)$  \n",
    "$ \\frac{\\partial{h}}{\\partial{W_i}} = X_i $  \n",
    "$ \\frac{\\partial{h}}{\\partial{b}} = 1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.params = {}\n",
    "        self.params['W'] = 0.01 * np.random.randn(2, 1)\n",
    "        self.params['b'] = np.ones(1)\n",
    "    def forward(self, X):\n",
    "        #Sigmoid 함수\n",
    "        W = self.params['W']\n",
    "        b = self.params['b']\n",
    "        h = np.dot(X, W) + b\n",
    "        p = 1 / (1 + np.exp(-h))\n",
    "        \n",
    "        return p\n",
    "    \n",
    "    def loss(self, X, T):\n",
    "        \n",
    "        p = self.forward(X)\n",
    "        \n",
    "        #Log_Likelihood\n",
    "        L = np.dot(T.reshape(1,200), np.log(p)) + np.dot(1 - T.reshape(1,200), np.log(1 - p))\n",
    "        L = np.squeeze(L)\n",
    "        #for i in range(len(X)):\n",
    "        #for문으로 각 데이터의 Log_Likelihood를 더해준다.\n",
    "        #    L += ( T[i] * np.log(p[i]) + (1 - T[i]) * np.log(1 - p[i]) )\n",
    "        \n",
    "        #목적함수는 -Log_Likelihood\n",
    "        return -L\n",
    "    \n",
    "    def gradient(self, X, T, learning_rate = 0.0001):\n",
    "        \n",
    "        p = self.forward(X)\n",
    "        #T = np.array(T)\n",
    "        T = T.reshape(-1,1)\n",
    "        #목적함수에 대한 가중치 미분값을 담을 zero array 생성\n",
    "        grads = {}\n",
    "        grads['W'] = np.zeros((2, 1))\n",
    "        grads['b'] = np.zeros(1)\n",
    "        \n",
    "        #목적함수에 대한 가중치 미분값 합 구하기\n",
    "        grads['W'] = -np.dot(X.T, (T - T*p) - (p - T*p))\n",
    "        grads['b'] = -np.sum((T - T*p) - (p - T*p))\n",
    "#         for i in range(len(X)):\n",
    "#             #for문으로 가중치에 대한 목적함수 미분 값 모두 더하기\n",
    "#             grads['W'] -= ((T[i] * (1-p[i])) - ((1-T[i]) * p[i])) * X[i].reshape(2,1)\n",
    "#             #print(i, \":  \", grads['W'])\n",
    "#             grads['b'] -= ((T[i] * (1-p[i])) - ((1-T[i]) * p[i])) * 1\n",
    "            \n",
    "#             if i == len(X) - 1:\n",
    "#                 grads['W'] /= len(X)\n",
    "#                 grads['b'] /= len(X)\n",
    "        self.params['W'] -= learning_rate * grads['W']\n",
    "        self.params['b'] -= learning_rate * grads['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"assignment_2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del data[\"bias\"]\n",
    "data[\"salary\"] = 0.0001 * data[\"salary\"]\n",
    "\n",
    "\n",
    "\n",
    "X = data[[\"experience\", \"salary\"]].values\n",
    "T = data[\"Label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73673392],\n",
       "       [0.73659074],\n",
       "       [0.73794744],\n",
       "       [0.73810166],\n",
       "       [0.73942951],\n",
       "       [0.73854061],\n",
       "       [0.73925172],\n",
       "       [0.74059953],\n",
       "       [0.73993791],\n",
       "       [0.73978402],\n",
       "       [0.73612568],\n",
       "       [0.73803068],\n",
       "       [0.73931063],\n",
       "       [0.73941766],\n",
       "       [0.73688872],\n",
       "       [0.74095337],\n",
       "       [0.73933482],\n",
       "       [0.73869497],\n",
       "       [0.73765047],\n",
       "       [0.73836266],\n",
       "       [0.73932308],\n",
       "       [0.73784002],\n",
       "       [0.74011552],\n",
       "       [0.73761452],\n",
       "       [0.74069381],\n",
       "       [0.73723355],\n",
       "       [0.74213094],\n",
       "       [0.73724583],\n",
       "       [0.73786357],\n",
       "       [0.74022197],\n",
       "       [0.74263614],\n",
       "       [0.73850558],\n",
       "       [0.73650744],\n",
       "       [0.73672199],\n",
       "       [0.74006795],\n",
       "       [0.73638819],\n",
       "       [0.73460722],\n",
       "       [0.74081204],\n",
       "       [0.73651914],\n",
       "       [0.73947691],\n",
       "       [0.73938199],\n",
       "       [0.73744808],\n",
       "       [0.73673392],\n",
       "       [0.73595851],\n",
       "       [0.73488267],\n",
       "       [0.73720984],\n",
       "       [0.73600608],\n",
       "       [0.73947667],\n",
       "       [0.73847006],\n",
       "       [0.73954764],\n",
       "       [0.73744808],\n",
       "       [0.73657832],\n",
       "       [0.73722175],\n",
       "       [0.73687668],\n",
       "       [0.73887277],\n",
       "       [0.73849358],\n",
       "       [0.73489453],\n",
       "       [0.73812556],\n",
       "       [0.73907445],\n",
       "       [0.73807813],\n",
       "       [0.73913327],\n",
       "       [0.73958293],\n",
       "       [0.73810178],\n",
       "       [0.74062316],\n",
       "       [0.73577896],\n",
       "       [0.73735292],\n",
       "       [0.73579128],\n",
       "       [0.73792317],\n",
       "       [0.73813697],\n",
       "       [0.73944112],\n",
       "       [0.74224863],\n",
       "       [0.73618481],\n",
       "       [0.73794671],\n",
       "       [0.73774568],\n",
       "       [0.73859998],\n",
       "       [0.73937014],\n",
       "       [0.74037521],\n",
       "       [0.73867134],\n",
       "       [0.73944148],\n",
       "       [0.73806636],\n",
       "       [0.73679332],\n",
       "       [0.73653095],\n",
       "       [0.73893221],\n",
       "       [0.74182528],\n",
       "       [0.74023344],\n",
       "       [0.74091843],\n",
       "       [0.73656712],\n",
       "       [0.73532519],\n",
       "       [0.74057614],\n",
       "       [0.73744796],\n",
       "       [0.74020979],\n",
       "       [0.73586289],\n",
       "       [0.73862373],\n",
       "       [0.73839867],\n",
       "       [0.73823242],\n",
       "       [0.73659074],\n",
       "       [0.73848086],\n",
       "       [0.73643594],\n",
       "       [0.74136598],\n",
       "       [0.73854121],\n",
       "       [0.74122444],\n",
       "       [0.73820841],\n",
       "       [0.73972518],\n",
       "       [0.74074094],\n",
       "       [0.73589778],\n",
       "       [0.73886126],\n",
       "       [0.73757881],\n",
       "       [0.7394416 ],\n",
       "       [0.73961907],\n",
       "       [0.73663835],\n",
       "       [0.73987897],\n",
       "       [0.73762618],\n",
       "       [0.73819689],\n",
       "       [0.74121276],\n",
       "       [0.73831561],\n",
       "       [0.73850497],\n",
       "       [0.73948864],\n",
       "       [0.74049342],\n",
       "       [0.74115377],\n",
       "       [0.73874209],\n",
       "       [0.73738889],\n",
       "       [0.74143649],\n",
       "       [0.73818464],\n",
       "       [0.73863536],\n",
       "       [0.73799429],\n",
       "       [0.74075275],\n",
       "       [0.74013894],\n",
       "       [0.7373291 ],\n",
       "       [0.73814934],\n",
       "       [0.73938175],\n",
       "       [0.73759083],\n",
       "       [0.73855236],\n",
       "       [0.73644764],\n",
       "       [0.73785203],\n",
       "       [0.73974898],\n",
       "       [0.73719768],\n",
       "       [0.73993827],\n",
       "       [0.73810191],\n",
       "       [0.73791151],\n",
       "       [0.73827984],\n",
       "       [0.74071803],\n",
       "       [0.73690053],\n",
       "       [0.73759071],\n",
       "       [0.73611374],\n",
       "       [0.7374245 ],\n",
       "       [0.7393705 ],\n",
       "       [0.7368762 ],\n",
       "       [0.73549226],\n",
       "       [0.73894372],\n",
       "       [0.7388259 ],\n",
       "       [0.739654  ],\n",
       "       [0.73836242],\n",
       "       [0.73880144],\n",
       "       [0.73666209],\n",
       "       [0.73754309],\n",
       "       [0.73662642],\n",
       "       [0.74018697],\n",
       "       [0.73768617],\n",
       "       [0.73513375],\n",
       "       [0.74090638],\n",
       "       [0.73755487],\n",
       "       [0.7413306 ],\n",
       "       [0.73893197],\n",
       "       [0.73785191],\n",
       "       [0.74189571],\n",
       "       [0.7374951 ],\n",
       "       [0.7392401 ],\n",
       "       [0.7388971 ],\n",
       "       [0.73799513],\n",
       "       [0.73775697],\n",
       "       [0.73869485],\n",
       "       [0.73698339],\n",
       "       [0.73939396],\n",
       "       [0.73960698],\n",
       "       [0.73751916],\n",
       "       [0.73877746],\n",
       "       [0.73818476],\n",
       "       [0.73729348],\n",
       "       [0.73717457],\n",
       "       [0.7388374 ],\n",
       "       [0.73937026],\n",
       "       [0.73788796],\n",
       "       [0.738066  ],\n",
       "       [0.73850485],\n",
       "       [0.73778089],\n",
       "       [0.73707935],\n",
       "       [0.73987933],\n",
       "       [0.73740068],\n",
       "       [0.73750713],\n",
       "       [0.73778101],\n",
       "       [0.73704347],\n",
       "       [0.74046966],\n",
       "       [0.73921651],\n",
       "       [0.73583898],\n",
       "       [0.74166033],\n",
       "       [0.74031634],\n",
       "       [0.73896745],\n",
       "       [0.73906247],\n",
       "       [0.7382317 ],\n",
       "       [0.73933434]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214.45453337245735"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.loss(X, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 Loss :  162.07983407268182\n",
      "10000 번째 Loss :  62.36711344701551\n",
      "20000 번째 Loss :  59.184836759112386\n",
      "30000 번째 Loss :  58.16938245213855\n",
      "40000 번째 Loss :  57.78084133330186\n",
      "50000 번째 Loss :  57.6169178953367\n",
      "60000 번째 Loss :  57.54364690465924\n",
      "70000 번째 Loss :  57.50968659626132\n",
      "80000 번째 Loss :  57.49356960148934\n",
      "90000 번째 Loss :  57.48579874722408\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    l.gradient(X, T)\n",
    "    if i % 10000 == 0:\n",
    "        print(i, \"번째 Loss : \", l.loss(X, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W': array([[ 1.57954273],\n",
       "        [-2.80429987]]), 'b': array([8.71042931])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
